This chapter discusses open-source software tools built and used in the previous chapters.
These tools were designed for general applications of this work and were written in the scientific computing language Julia \cite{bezanson2017julia}.
Open-source software is important for safety validation as it encourages reproducibility and enables others to apply these methods to different applications.
More importantly, we view the field of validation as collaborative and non-competitive because ultimately safer systems benefit us all.
We first discuss the adaptive stress testing package built for \cref{cha:episodic_ast}, then provide quick usage examples of the optimization package built for \cref{cha:cem_variants} and the weakness recognition framework built for \cref{cha:weakness_rec}. All software packages described in this section are publicly available under the MIT license.


\section{POMDPStressTesting.jl Summary}\label{sec:pomdpstresstesting}
POMDPStressTesting.jl\footnote{\url{https://github.com/sisl/POMDPStressTesting.jl}} is a package that uses reinforcement learning and stochastic optimization to find likely failures in black-box systems using adaptive stress testing \cite{lee2019adaptive}.
The POMDPStressTesting.jl package is written in Julia \cite{bezanson2017julia} and is part of the wider POMDPs.jl ecosystem \cite{pomdps_jl}, which provides access to simulation tools, policies, visualizations, and---most importantly---solvers.
We provide different solver variants including online planning algorithms such as Monte Carlo tree search \cite{coulom2006efficient} and deep reinforcement learning algorithms such as trust region policy optimization (TRPO) \cite{trpo} and proximal policy optimization (PPO) \cite{ppo}.
Stochastic optimization solvers such as the cross-entropy method \cite{rubinstein1999cross} are also available and random search is provided as a baseline.
Additional solvers can easily be added by adhering to the POMDPs.jl interface.


\subsection{Interface and Related Software}
The AST formulation treats the falsification problem (i.e., finding failures) as a Markov decision process (MDP) with a reward function that uses a measure of distance to a failure event to guide the search towards failure.
The reward function also uses the state transition probabilities to guide towards \textit{likely} failures.
Reinforcement learning aims to maximize the discounted sum of expected rewards, therefore maximizing the sum of log-likelihoods is equivalent to maximizing the likelihood of a trajectory.
A gray-box simulation environment steps the simulation and outputs the state transition probabilities, and the black-box system under test is evaluated in the simulator and outputs an event indication and the real-valued distance metric (i.e., how close we are to failure).
To apply AST to a general black-box system, a user has to implement the following Julia interface:
\input{algorithms/pomdp-stress-testing-interface}


Our package builds off work originally done in the AdaptiveStressTesting.jl package \cite{lee2019adaptive}, but POMDPStressTesting.jl adheres to the interface defined by POMDPs.jl and provides different action modes and solver types.
Related falsification tools (i.e., tools that do not include most-likely failure analysis) are \textsc{S-TaLiRo} \cite{annapureddy2011staliro}, Breach \cite{breach}, and \textsc{FalStar} \cite{falstar}.
These packages use a combination of optimization, path planning, and reinforcement learning techniques to solve the falsification problem.
The tool most closely related to POMDPStressTesting.jl is the AST Toolbox in Python \cite{koren2018adaptive}, which wraps around the gym reinforcement learning environment \cite{gym}.
The author has contributed to the AST Toolbox and found the need to create a similar package in pure Julia for better performance and to interface with the POMDPs.jl ecosystem.


\subsection{Statement of Need}
Validating autonomous systems is a crucial requirement before their deployment into real-world environments.
Searching for likely failures using automated tools enable engineers to address potential problems during development.
Because many autonomous systems are in environments with rare failure events, it is especially important to incorporate likelihood of failure within the search to help inform the potential problem mitigation.
This tool provides a simple interface for general black-box systems to fit into the adaptive stress testing problem formulation and gain access to solvers.
Due to varying simulation environment complexities, random seeds can be used as the AST action when the user does not have direct access to the environmental probability distributions or when the environment is complex.
Alternatively, directly sampling from the distributions allows for finer control over the search.
The interface is designed to easily extend to other autonomous system applications and explicitly separating the simulation environment from the system under test allows for wider validation of complex black-box systems.



\subsection{Research and Industrial Usage}
POMDPStressTesting.jl has been used to find likely failures in aircraft trajectory prediction systems (\cref{cha:episodic_ast}) \cite{moss2020adaptive}, which are flight-critical subsystems used to aid in-flight automation.
This software was used to stress test a development commercial FMS so that the system engineers could mitigate potential issues before system deployment.
In addition to traditional requirements-based testing for avionics certification \cite{do178c}, this work is being used to find potential problems during development.
There has also been research on the use of POMDPStressTesting.jl for assessing the risk of autonomous vehicles and determining failure scenarios of autonomous lunar rovers.



\section{CrossEntropyVariants.jl Summary}
The CrossEntropyVariants.jl\footnote{\url{https://github.com/mossr/CrossEntropyVariants.jl}} package provides a general implementation of the algorithms introduced in \cref{cha:cem_variants}.
Specifically, we provide the following algorithms that take an objective function $S$ and initial proposal distribution $\M$ as input, and output an optimized distribution $\M'$:

\input{algorithms/cem-variants-functions}

To illustrate why we found Julia to be our language of choice, below we present a slightly cleaned-up version of our actual implementation of \cref{alg:ce_surrogate} (i.e., the \textsc{CE-Surrogate} algorithm), noting the direct translation of the pseudocode into executable Julia code:

\input{algorithms/ce-surrogate}

As an example, to run an simple optimization problem, consider the following code:
\input{algorithms/cem-variants-usage}
Here we select the \texttt{sierra} test function described in \cref{sec:sierra} and optimize a multivariate Gaussian proposal distribution $\mathbf{M}$ using a call to \texttt{ce\_surrogate}.

The performance of the surrogate models may be dependent on the underlying objective function. The default surrogate model is a Gaussian process with the squared exponential kernel function, yet we provide other surrogate models including linear regression, polynomial regression, and radial basis regression. As an example, to use radial basis regression instead of a Gaussian process, you can specify a \texttt{basis} keyword input:
\input{algorithms/cem-variants-usage-basis}

Our package relies an other open-source Julia software including Distributions.jl \cite{distributions.jl}, GaussianMixtures.jl,\footnote{\url{https://github.com/davidavdav/GaussianMixtures.jl}} GaussianProcesses.jl \cite{gaussianprocesses.jl}, and Optim.jl \cite{mogensen2018optim}. Their own open-source contributions enabled the quick prototyping of our software and we appreciate their effort and commitment to open-source software. We were inspired by \citefull{kochenderfer2019algorithms} and borrowed the \texttt{cross\_entropy\_method} algorithm from their work.


\section{FailureRepresentation.jl Summary}
The FailureRepresentation.jl\footnote{\url{https://github.com/sisl/FailureRepresentation.jl}} package captures the work from \cref{cha:weakness_rec} primarily for reproducibility but can also be extended to other black-box systems aside from the MNIST neural network classifier.
This requires the user to define a \texttt{predict(â„³, x)} function given their system $\mathcal M$ and input $x$, replacing the \texttt{SystemUnderTest} module within the framework.
We also provide experiment code and pre-trained adversarial models produced from \cref{cha:weakness_rec}.

A sample usage would load the user-defined system under test and the adversarial autoencoder, then call the \texttt{sampled\_validation\_iteration} function illustrated in \cref{fig:framework}.
